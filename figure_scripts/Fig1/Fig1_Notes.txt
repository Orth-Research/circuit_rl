/Users/msohaibalam/Documents/RLQC/RL_1q_state_prep/1q Rotation gates/RL_discrete_1q_lambda_run_v20p3-Copy1.ipynb --> RL_discrete_1q_Fig1.ipynb (produces Fig. 1)

/Users/msohaibalam/Documents/RLQC/RL_1q_state_prep/optimal_policy_discrete_1q_v20.p (^ uses this file)

^ was generated by running RL_discrete_1q_space_v20_lambda.py on lambda machine.

RL_discrete_1q_lambda_run_v20.ipynb uses K=1
RL_discrete_1q_lambda_run_v20.ipynb uses K=1, but with a slightly different environment using a different definition of "reset" as used in the file RL_discrete_1q_space_v20_lambda.py (to generate the optimal policy)

Finally,
RL_discrete_1q_Fig1.ipynb uses K=100.

We used 10,000 randomly drawn states on the Bloch sphere, then looped over all the actions to estimate the transition probabilities p(s',r|s,a).
